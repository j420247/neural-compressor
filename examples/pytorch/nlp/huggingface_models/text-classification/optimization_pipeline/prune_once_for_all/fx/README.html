<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Step-by-Step &mdash; Intel® Neural Compressor  documentation</title><link rel="stylesheet" href="../../../../../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../../../../../../" src="../../../../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../../../../_static/jquery.js"></script>
        <script src="../../../../../../../../_static/underscore.js"></script>
        <script src="../../../../../../../../_static/doctools.js"></script>
    <script src="../../../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../../../../../index.html" class="icon icon-home"> Intel® Neural Compressor
          </a>
              <div class="version">
                1.14.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../README.html">Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../api-documentation/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/doclist.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../../../index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../../../index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Step-by-Step</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../../../_sources/examples/pytorch/nlp/huggingface_models/text-classification/optimization_pipeline/prune_once_for_all/fx/README.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="step-by-step">
<h1>Step-by-Step<a class="headerlink" href="#step-by-step" title="Permalink to this headline">¶</a></h1>
<p>This document is used to list steps of reproducing Prune Once For All examples result.
<br>
These examples will take the pre-trained sparse language model and fine tune it on the several downstream tasks. This fine tune pipeline is two staged. For stage 1, the pattern lock pruning and the distillation are applied to fine tune the pre-trained sparse language model. In stage 2, the pattern lock pruning, distillation and quantization aware training are performed simultaneously on the fine tuned model from stage 1 to obtain the quantized model with the same sparsity pattern as the pre-trained sparse language model.
<br>
For more informations of this algorithm, please refer to the paper <a class="reference external" href="https://arxiv.org/abs/2111.05754">Prune Once For All: Sparse Pre-Trained Language Models</a></p>
</div>
<div class="section" id="prerequisite">
<h1>Prerequisite<a class="headerlink" href="#prerequisite" title="Permalink to this headline">¶</a></h1>
<div class="section" id="python-version">
<h2>Python Version<a class="headerlink" href="#python-version" title="Permalink to this headline">¶</a></h2>
<p>Recommend python 3.6 or higher version.</p>
</div>
<div class="section" id="install-dependency">
<h2>Install dependency<a class="headerlink" href="#install-dependency" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip install -r requirements.txt
</pre></div>
</div>
</div>
</div>
<div class="section" id="start-running-neural-compressor-implementation-of-prune-once-for-all">
<h1>Start running neural_compressor implementation of Prune Once For All<a class="headerlink" href="#start-running-neural-compressor-implementation-of-prune-once-for-all" title="Permalink to this headline">¶</a></h1>
<p>Below are example NLP tasks for Prune Once For All to fine tune the sparse BERT model on the specific task.
<br>
It requires the pre-trained task specific model such as <code class="docutils literal notranslate"><span class="pre">textattack/roberta-base-SST-2</span></code> from textattack Huggingface portal as the teacher model for distillation, also the pre-trained sparse BERT model such as <code class="docutils literal notranslate"><span class="pre">Intel/bert-base-uncased-sparse-90-unstructured-pruneofa</span></code> from Intel Huggingface portal as the model for fine tuning.
<br>
The pattern lock pruning configuration is specified in yaml file i.e. prune.yaml, the quantization aware training configuration is specified in yaml file i.e. qat.yaml.</p>
<div class="section" id="sst-2-task">
<h2>SST-2 task<a class="headerlink" href="#sst-2-task" title="Permalink to this headline">¶</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># for stage 1</span>
python run_glue_no_trainer_pruneOFA.py --task_name sst2 <span class="se">\</span>
      --model_name_or_path Intel/bert-base-uncased-sparse-90-unstructured-pruneofa <span class="se">\</span>
      --teacher_model_name_or_path textattack/bert-base-uncased-SST-2 <span class="se">\</span>
      --do_prune --do_distillation --max_seq_length <span class="m">128</span> --batch_size <span class="m">32</span> <span class="se">\</span>
      --learning_rate 1e-4 --num_train_epochs <span class="m">9</span> --output_dir /path/to/stage1_output_dir <span class="se">\</span>
      --loss_weights <span class="m">0</span> <span class="m">1</span> --temperature <span class="m">2</span> --seed <span class="m">5143</span>
<span class="c1"># for stage 2</span>
python run_glue_no_trainer_pruneOFA.py --task_name sst2 <span class="se">\</span>
      --model_name_or_path Intel/bert-base-uncased-sparse-90-unstructured-pruneofa <span class="se">\</span>
      --teacher_model_name_or_path textattack/bert-base-uncased-SST-2 <span class="se">\</span>
      --do_prune --do_distillation --max_seq_length <span class="m">128</span> --batch_size <span class="m">32</span> <span class="se">\</span>
      --learning_rate 1e-5 --num_train_epochs <span class="m">3</span> --output_dir /path/to/stage2_output_dir <span class="se">\</span>
      --loss_weights <span class="m">0</span> <span class="m">1</span> --temperature <span class="m">2</span> --seed <span class="m">5143</span> --do_quantization <span class="se">\</span>
      --resume /path/to/stage1_output_dir/best_model.pt --pad_to_max_length
</pre></div>
</div>
</div>
<div class="section" id="mnli-task">
<h2>MNLI task<a class="headerlink" href="#mnli-task" title="Permalink to this headline">¶</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># for stage 1</span>
python run_glue_no_trainer_pruneOFA.py --task_name mnli <span class="se">\</span>
      --model_name_or_path Intel/bert-base-uncased-sparse-90-unstructured-pruneofa <span class="se">\</span>
      --teacher_model_name_or_path blackbird/bert-base-uncased-MNLI-v1 <span class="se">\</span>
      --do_prune --do_distillation --max_seq_length <span class="m">128</span> --batch_size <span class="m">32</span> <span class="se">\</span>
      --learning_rate 1e-4 --num_train_epochs <span class="m">9</span> --output_dir /path/to/stage1_output_dir <span class="se">\</span>
      --loss_weights <span class="m">0</span> <span class="m">1</span> --temperature <span class="m">2</span> --seed <span class="m">5143</span>
<span class="c1"># for stage 2</span>
python run_glue_no_trainer_pruneOFA.py --task_name mnli <span class="se">\</span>
      --model_name_or_path Intel/bert-base-uncased-sparse-90-unstructured-pruneofa <span class="se">\</span>
      --teacher_model_name_or_path blackbird/bert-base-uncased-MNLI-v1 <span class="se">\</span>
      --do_prune --do_distillation --max_seq_length <span class="m">128</span> --batch_size <span class="m">32</span> <span class="se">\</span>
      --learning_rate 1e-5 --num_train_epochs <span class="m">3</span> --output_dir /path/to/stage2_output_dir <span class="se">\</span>
      --loss_weights <span class="m">0</span> <span class="m">1</span> --temperature <span class="m">2</span> --seed <span class="m">5143</span> --do_quantization <span class="se">\</span>
      --resume /path/to/stage1_output_dir/best_model.pt --pad_to_max_length
</pre></div>
</div>
</div>
<div class="section" id="qqp-task">
<h2>QQP task<a class="headerlink" href="#qqp-task" title="Permalink to this headline">¶</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># for stage 1</span>
python run_glue_no_trainer_pruneOFA.py --task_name qqp <span class="se">\</span>
      --model_name_or_path Intel/bert-base-uncased-sparse-90-unstructured-pruneofa <span class="se">\</span>
      --teacher_model_name_or_path textattack/bert-base-uncased-QQP <span class="se">\</span>
      --do_prune --do_distillation --max_seq_length <span class="m">128</span> --batch_size <span class="m">32</span> <span class="se">\</span>
      --learning_rate 1e-4 --num_train_epochs <span class="m">9</span> --output_dir /path/to/stage1_output_dir <span class="se">\</span>
      --loss_weights <span class="m">0</span> <span class="m">1</span> --temperature <span class="m">2</span> --seed <span class="m">5143</span>
<span class="c1"># for stage 2</span>
python run_glue_no_trainer_pruneOFA.py --task_name qqp <span class="se">\</span>
      --model_name_or_path Intel/bert-base-uncased-sparse-90-unstructured-pruneofa <span class="se">\</span>
      --teacher_model_name_or_path textattack/bert-base-uncased-QQP <span class="se">\</span>
      --do_prune --do_distillation --max_seq_length <span class="m">128</span> --batch_size <span class="m">32</span> <span class="se">\</span>
      --learning_rate 1e-5 --num_train_epochs <span class="m">3</span> --output_dir /path/to/stage2_output_dir <span class="se">\</span>
      --loss_weights <span class="m">0</span> <span class="m">1</span> --temperature <span class="m">2</span> --seed <span class="m">5143</span> --do_quantization <span class="se">\</span>
      --resume /path/to/stage1_output_dir/best_model.pt --pad_to_max_length
</pre></div>
</div>
</div>
<div class="section" id="qnli-task">
<h2>QNLI task<a class="headerlink" href="#qnli-task" title="Permalink to this headline">¶</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># for stage 1</span>
python run_glue_no_trainer_pruneOFA.py --task_name qnli <span class="se">\</span>
      --model_name_or_path Intel/bert-base-uncased-sparse-90-unstructured-pruneofa <span class="se">\</span>
      --teacher_model_name_or_path textattack/bert-base-uncased-QNLI <span class="se">\</span>
      --do_prune --do_distillation --max_seq_length <span class="m">128</span> --batch_size <span class="m">32</span> <span class="se">\</span>
      --learning_rate 1e-4 --num_train_epochs <span class="m">9</span> --output_dir /path/to/stage1_output_dir <span class="se">\</span>
      --loss_weights <span class="m">0</span> <span class="m">1</span> --temperature <span class="m">2</span> --seed <span class="m">5143</span>
<span class="c1"># for stage 2</span>
python run_glue_no_trainer_pruneOFA.py --task_name qnli <span class="se">\</span>
      --model_name_or_path Intel/bert-base-uncased-sparse-90-unstructured-pruneofa <span class="se">\</span>
      --teacher_model_name_or_path textattack/bert-base-uncased-QNLI <span class="se">\</span>
      --do_prune --do_distillation --max_seq_length <span class="m">128</span> --batch_size <span class="m">32</span> <span class="se">\</span>
      --learning_rate 1e-5 --num_train_epochs <span class="m">3</span> --output_dir /path/to/stage2_output_dir <span class="se">\</span>
      --loss_weights <span class="m">0</span> <span class="m">1</span> --temperature <span class="m">2</span> --seed <span class="m">5143</span> --do_quantization <span class="se">\</span>
      --resume /path/to/stage1_output_dir/best_model.pt --pad_to_max_length
</pre></div>
</div>
<p>We also supported Distributed Data Parallel training on single node and multi nodes settings. To use Distributed Data Parallel to speedup training, the bash command needs a small adjustment.
<br>
For example, bash command of stage 1 for SST2 task will look like the following, where <em><code class="docutils literal notranslate"><span class="pre">&lt;MASTER_ADDRESS&gt;</span></code></em> is the address of the master node, it won’t be necessary for single node case, <em><code class="docutils literal notranslate"><span class="pre">&lt;NUM_PROCESSES_PER_NODE&gt;</span></code></em> is the desired processes to use in current node, for node with GPU, usually set to number of GPUs in this node, for node without GPU and use CPU for training, it’s recommended set to 1, <em><code class="docutils literal notranslate"><span class="pre">&lt;NUM_NODES&gt;</span></code></em> is the number of nodes to use, <em><code class="docutils literal notranslate"><span class="pre">&lt;NODE_RANK&gt;</span></code></em> is the rank of the current node, rank starts from 0 to <em><code class="docutils literal notranslate"><span class="pre">&lt;NUM_NODES&gt;</span></code></em><code class="docutils literal notranslate"><span class="pre">-1</span></code>.
<br>
Also please note that to use CPU for training in each node with multi nodes settings, argument <code class="docutils literal notranslate"><span class="pre">--no_cuda</span></code> is mandatory. In multi nodes setting, following command needs to be lanuched in each node, and all the commands should be the same except for <em><code class="docutils literal notranslate"><span class="pre">&lt;NODE_RANK&gt;</span></code></em>, which should be integer from 0 to <em><code class="docutils literal notranslate"><span class="pre">&lt;NUM_NODES&gt;</span></code></em><code class="docutils literal notranslate"><span class="pre">-1</span></code> assigned to each node.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python -m torch.distributed.launch --master_addr<span class="o">=</span>&lt;MASTER_ADDRESS&gt; --nproc_per_node<span class="o">=</span>&lt;NUM_PROCESSES_PER_NODE&gt; --nnodes<span class="o">=</span>&lt;NUM_NODES&gt; --node_rank<span class="o">=</span>&lt;NODE_RANK&gt; <span class="se">\</span>
      run_glue_no_trainer_pruneOFA.py --task_name sst2 <span class="se">\</span>
      --model_name_or_path Intel/bert-base-uncased-sparse-90-unstructured-pruneofa <span class="se">\</span>
      --teacher_model_name_or_path textattack/bert-base-uncased-SST-2 <span class="se">\</span>
      --do_prune --do_distillation --max_seq_length <span class="m">128</span> --batch_size <span class="m">32</span> <span class="se">\</span>
      --learning_rate 1e-4 --num_train_epochs <span class="m">9</span> --output_dir /path/to/stage1_output_dir <span class="se">\</span>
      --loss_weights <span class="m">0</span> <span class="m">1</span> --temperature <span class="m">2</span> --seed <span class="m">5143</span>
</pre></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Neural Compressor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>