<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Movement Pruning: Adaptive Sparsity by Fine-Tuning &mdash; IntelÂ® Neural Compressor  documentation</title><link rel="stylesheet" href="../../../../../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../../../../../../" src="../../../../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../../../../_static/jquery.js"></script>
        <script src="../../../../../../../../_static/underscore.js"></script>
        <script src="../../../../../../../../_static/doctools.js"></script>
    <script src="../../../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../../../../../index.html" class="icon icon-home"> IntelÂ® Neural Compressor
          </a>
              <div class="version">
                1.14.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../README.html">IntelÂ® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../api-documentation/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/doclist.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../../docs/legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">IntelÂ® Neural Compressor repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../../../index.html">IntelÂ® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../../../index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Movement Pruning: Adaptive Sparsity by Fine-Tuning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../../../_sources/examples/pytorch/nlp/huggingface_models/common/examples/research_projects/movement-pruning/README.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="movement-pruning-adaptive-sparsity-by-fine-tuning">
<h1>Movement Pruning: Adaptive Sparsity by Fine-Tuning<a class="headerlink" href="#movement-pruning-adaptive-sparsity-by-fine-tuning" title="Permalink to this headline">Â¶</a></h1>
<p>Author: &#64;VictorSanh</p>
<p><em>Magnitude pruning is a widely used strategy for reducing model size in pure supervised learning; however, it is less effective in the transfer learning regime that has become standard for state-of-the-art natural language processing applications. We propose the use of <em>movement pruning</em>, a simple, deterministic first-order weight pruning method that is more adaptive to pretrained model fine-tuning. Experiments show that when pruning large pretrained language models, movement pruning shows significant improvements in high-sparsity regimes. When combined with distillation, the approach achieves minimal accuracy loss with down to only 3% of the model parameters:</em></p>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: center;">Fine-pruning+Distillation<br>(Teacher=BERT-base fine-tuned)</th>
<th style="text-align: center;">BERT base<br>fine-tuned</th>
<th style="text-align: center;">Remaining<br>Weights (%)</th>
<th style="text-align: center;">Magnitude Pruning</th>
<th style="text-align: center;">L0 Regularization</th>
<th style="text-align: center;">Movement Pruning</th>
<th style="text-align: center;">Soft Movement Pruning</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">SQuAD - Dev<br>EM/F1</td>
<td style="text-align: center;">80.4/88.1</td>
<td style="text-align: center;">10%<br>3%</td>
<td style="text-align: center;">70.2/80.1<br>45.5/59.6</td>
<td style="text-align: center;">72.4/81.9<br>64.3/75.8</td>
<td style="text-align: center;">75.6/84.3<br>67.5/78.0</td>
<td style="text-align: center;"><strong>76.6/84.9</strong><br><strong>72.7/82.3</strong></td>
</tr>
<tr>
<td style="text-align: center;">MNLI - Dev<br>acc/MM acc</td>
<td style="text-align: center;">84.5/84.9</td>
<td style="text-align: center;">10%<br>3%</td>
<td style="text-align: center;">78.3/79.3<br>69.4/70.6</td>
<td style="text-align: center;">78.7/79.7<br>76.0/76.2</td>
<td style="text-align: center;">80.1/80.4<br>76.5/77.4</td>
<td style="text-align: center;"><strong>81.2/81.8</strong><br><strong>79.5/80.1</strong></td>
</tr>
<tr>
<td style="text-align: center;">QQP - Dev<br>acc/F1</td>
<td style="text-align: center;">91.4/88.4</td>
<td style="text-align: center;">10%<br>3%</td>
<td style="text-align: center;">79.8/65.0<br>72.4/57.8</td>
<td style="text-align: center;">88.1/82.8<br>87.0/81.9</td>
<td style="text-align: center;">89.7/86.2<br>86.1/81.5</td>
<td style="text-align: center;"><strong>90.2/86.8</strong><br><strong>89.1/85.5</strong></td>
</tr>
</tbody>
</table><p>This page contains information on how to fine-prune pre-trained models such as <code class="docutils literal notranslate"><span class="pre">BERT</span></code> to obtain extremely sparse models with movement pruning. In contrast to magnitude pruning which selects weights that are far from 0, movement pruning retains weights that are moving away from 0.</p>
<p>For more information, we invite you to check out <a class="reference external" href="https://arxiv.org/abs/2005.07683">our paper</a>.
You can also have a look at this fun <em>Explain Like Iâ€™m Five</em> introductory <a class="reference external" href="https://www.slideshare.net/VictorSanh/movement-pruning-explain-like-im-five-234205241">slide deck</a>.</p>
<div align="center">
<img src="https://www.seekpng.com/png/detail/166-1669328_how-to-make-emmental-cheese-at-home-icooker.png" width="400">
</div><div class="section" id="extreme-sparsity-and-efficient-storage">
<h2>Extreme sparsity and efficient storage<a class="headerlink" href="#extreme-sparsity-and-efficient-storage" title="Permalink to this headline">Â¶</a></h2>
<p>One promise of extreme pruning is to obtain extremely small models that can be easily sent (and stored) on edge devices. By setting weights to 0., we reduce the amount of information we need to store, and thus decreasing the memory size. We are able to obtain extremely sparse fine-pruned models with movement pruning: ~95% of the dense performance with ~5% of total remaining weights in the BERT encoder.</p>
<p>In <a class="reference external" href="https://github.com/huggingface/transformers/blob/master/examples/movement-pruning/Saving_PruneBERT.ipynb">this notebook</a>, we showcase how we can leverage standard tools that exist out-of-the-box to efficiently store an extremely sparse question answering model (only 6% of total remaining weights in the encoder). We are able to reduce the memory size of the encoder <strong>from the 340MB (the original dense BERT) to 11MB</strong>, without any additional training of the model (every operation is performed <em>post fine-pruning</em>). It is sufficiently small to store it on a <a class="reference external" href="https://en.wikipedia.org/wiki/Floptical">91â€™ floppy disk</a> ðŸ“Ž!</p>
<p>While movement pruning does not directly optimize for memory footprint (but rather the number of non-null weights), we hypothetize that further memory compression ratios can be achieved with specific quantization aware trainings (see for instance <a class="reference external" href="https://arxiv.org/abs/1910.06188">Q8BERT</a>, <a class="reference external" href="https://arxiv.org/abs/1907.05686">And the Bit Goes Down</a> or <a class="reference external" href="https://arxiv.org/abs/2004.07320">Quant-Noise</a>).</p>
</div>
<div class="section" id="fine-pruned-models">
<h2>Fine-pruned models<a class="headerlink" href="#fine-pruned-models" title="Permalink to this headline">Â¶</a></h2>
<p>As examples, we release two English PruneBERT checkpoints (models fine-pruned from a pre-trained <code class="docutils literal notranslate"><span class="pre">BERT</span></code> checkpoint), one on SQuAD and the other on MNLI.</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">prunebert-base-uncased-6-finepruned-w-distil-squad</span></code></strong><br/>
Pre-trained <code class="docutils literal notranslate"><span class="pre">BERT-base-uncased</span></code> fine-pruned with soft movement pruning on SQuAD v1.1. We use an additional distillation signal from <code class="docutils literal notranslate"><span class="pre">BERT-base-uncased</span></code> finetuned on SQuAD. The encoder counts 6% of total non-null weights and reaches 83.8 F1 score. The model can be accessed with: <code class="docutils literal notranslate"><span class="pre">pruned_bert</span> <span class="pre">=</span> <span class="pre">BertForQuestionAnswering.from_pretrained(&quot;huggingface/prunebert-base-uncased-6-finepruned-w-distil-squad&quot;)</span></code></p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">prunebert-base-uncased-6-finepruned-w-distil-mnli</span></code></strong><br/>
Pre-trained <code class="docutils literal notranslate"><span class="pre">BERT-base-uncased</span></code> fine-pruned with soft movement pruning on MNLI. We use an additional distillation signal from <code class="docutils literal notranslate"><span class="pre">BERT-base-uncased</span></code> finetuned on MNLI. The encoder counts 6% of total non-null weights and reaches 80.7 (matched) accuracy. The model can be accessed with: <code class="docutils literal notranslate"><span class="pre">pruned_bert</span> <span class="pre">=</span> <span class="pre">BertForSequenceClassification.from_pretrained(&quot;huggingface/prunebert-base-uncased-6-finepruned-w-distil-mnli&quot;)</span></code></p></li>
</ul>
</div>
<div class="section" id="how-to-fine-prune">
<h2>How to fine-prune?<a class="headerlink" href="#how-to-fine-prune" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="setup">
<h3>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">Â¶</a></h3>
<p>The code relies on the ðŸ¤— Transformers library. In addition to the dependencies listed in the <a class="reference external" href="https://github.com/huggingface/transformers/tree/master/examples"><code class="docutils literal notranslate"><span class="pre">examples</span></code></a> folder, you should install a few additional dependencies listed in the <code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code> file: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">-r</span> <span class="pre">requirements.txt</span></code>.</p>
<p>Note that we built our experiments on top of a stabilized version of the library (commit https://github.com/huggingface/transformers/commit/352d5472b0c1dec0f420d606d16747d851b4bda8): we do not guarantee that everything is still compatible with the latest version of the master branch.</p>
</div>
<div class="section" id="fine-pruning-with-movement-pruning">
<h3>Fine-pruning with movement pruning<a class="headerlink" href="#fine-pruning-with-movement-pruning" title="Permalink to this headline">Â¶</a></h3>
<p>Below, we detail how to reproduce the results reported in the paper. We use SQuAD as a running example. Commands (and scripts) can be easily adapted for other tasks.</p>
<p>The following command fine-prunes a pre-trained <code class="docutils literal notranslate"><span class="pre">BERT-base</span></code> on SQuAD using movement pruning towards 15% of remaining weights (85% sparsity). Note that we freeze all the embeddings modules (from their pre-trained value) and only prune the Fully Connected layers in the encoder (12 layers of Transformer Block).</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">SERIALIZATION_DIR</span><span class="o">=</span>&lt;OUTPUT_DIR&gt;
<span class="nv">SQUAD_DATA</span><span class="o">=</span>&lt;SQUAD_DATA&gt;

python examples/movement-pruning/masked_run_squad.py <span class="se">\</span>
    --output_dir <span class="nv">$SERIALIZATION_DIR</span> <span class="se">\</span>
    --data_dir <span class="nv">$SQUAD_DATA</span> <span class="se">\</span>
    --train_file train-v1.1.json <span class="se">\</span>
    --predict_file dev-v1.1.json <span class="se">\</span>
    --do_train --do_eval --do_lower_case <span class="se">\</span>
    --model_type masked_bert <span class="se">\</span>
    --model_name_or_path bert-base-uncased <span class="se">\</span>
    --per_gpu_train_batch_size <span class="m">16</span> <span class="se">\</span>
    --warmup_steps <span class="m">5400</span> <span class="se">\</span>
    --num_train_epochs <span class="m">10</span> <span class="se">\</span>
    --learning_rate 3e-5 --mask_scores_learning_rate 1e-2 <span class="se">\</span>
    --initial_threshold <span class="m">1</span> --final_threshold <span class="m">0</span>.15 <span class="se">\</span>
    --initial_warmup <span class="m">1</span> --final_warmup <span class="m">2</span> <span class="se">\</span>
    --pruning_method topK --mask_init constant --mask_scale <span class="m">0</span>.
</pre></div>
</div>
</div>
<div class="section" id="fine-pruning-with-other-methods">
<h3>Fine-pruning with other methods<a class="headerlink" href="#fine-pruning-with-other-methods" title="Permalink to this headline">Â¶</a></h3>
<p>We can also explore other fine-pruning methods by changing the <code class="docutils literal notranslate"><span class="pre">pruning_method</span></code> parameter:</p>
<p>Soft movement pruning</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python examples/movement-pruning/masked_run_squad.py <span class="se">\</span>
    --output_dir <span class="nv">$SERIALIZATION_DIR</span> <span class="se">\</span>
    --data_dir <span class="nv">$SQUAD_DATA</span> <span class="se">\</span>
    --train_file train-v1.1.json <span class="se">\</span>
    --predict_file dev-v1.1.json <span class="se">\</span>
    --do_train --do_eval --do_lower_case <span class="se">\</span>
    --model_type masked_bert <span class="se">\</span>
    --model_name_or_path bert-base-uncased <span class="se">\</span>
    --per_gpu_train_batch_size <span class="m">16</span> <span class="se">\</span>
    --warmup_steps <span class="m">5400</span> <span class="se">\</span>
    --num_train_epochs <span class="m">10</span> <span class="se">\</span>
    --learning_rate 3e-5 --mask_scores_learning_rate 1e-2 <span class="se">\</span>
    --initial_threshold <span class="m">0</span> --final_threshold <span class="m">0</span>.1 <span class="se">\</span>
    --initial_warmup <span class="m">1</span> --final_warmup <span class="m">2</span> <span class="se">\</span>
    --pruning_method sigmoied_threshold --mask_init constant --mask_scale <span class="m">0</span>. <span class="se">\</span>
    --regularization l1 --final_lambda <span class="m">400</span>.
</pre></div>
</div>
<p>L0 regularization</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python examples/movement-pruning/masked_run_squad.py <span class="se">\</span>
    --output_dir <span class="nv">$SERIALIZATION_DIR</span> <span class="se">\</span>
    --data_dir <span class="nv">$SQUAD_DATA</span> <span class="se">\</span>
    --train_file train-v1.1.json <span class="se">\</span>
    --predict_file dev-v1.1.json <span class="se">\</span>
    --do_train --do_eval --do_lower_case <span class="se">\</span>
    --model_type masked_bert <span class="se">\</span>
    --model_name_or_path bert-base-uncased <span class="se">\</span>
    --per_gpu_train_batch_size <span class="m">16</span> <span class="se">\</span>
    --warmup_steps <span class="m">5400</span> <span class="se">\</span>
    --num_train_epochs <span class="m">10</span> <span class="se">\</span>
    --learning_rate 3e-5 --mask_scores_learning_rate 1e-1 <span class="se">\</span>
    --initial_threshold <span class="m">1</span>. --final_threshold <span class="m">1</span>. <span class="se">\</span>
    --initial_warmup <span class="m">1</span> --final_warmup <span class="m">1</span> <span class="se">\</span>
    --pruning_method l0 --mask_init constant --mask_scale <span class="m">2</span>.197 <span class="se">\</span>
    --regularization l0 --final_lambda <span class="m">125</span>.
</pre></div>
</div>
<p>Iterative Magnitude Pruning</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python examples/movement-pruning/masked_run_squad.py <span class="se">\</span>
    --output_dir ./dbg <span class="se">\</span>
    --data_dir examples/distillation/data/squad_data <span class="se">\</span>
    --train_file train-v1.1.json <span class="se">\</span>
    --predict_file dev-v1.1.json <span class="se">\</span>
    --do_train --do_eval --do_lower_case <span class="se">\</span>
    --model_type masked_bert <span class="se">\</span>
    --model_name_or_path bert-base-uncased <span class="se">\</span>
    --per_gpu_train_batch_size <span class="m">16</span> <span class="se">\</span>
    --warmup_steps <span class="m">5400</span> <span class="se">\</span>
    --num_train_epochs <span class="m">10</span> <span class="se">\</span>
    --learning_rate 3e-5 <span class="se">\</span>
    --initial_threshold <span class="m">1</span> --final_threshold <span class="m">0</span>.15 <span class="se">\</span>
    --initial_warmup <span class="m">1</span> --final_warmup <span class="m">2</span> <span class="se">\</span>
    --pruning_method magnitude
</pre></div>
</div>
</div>
<div class="section" id="after-fine-pruning">
<h3>After fine-pruning<a class="headerlink" href="#after-fine-pruning" title="Permalink to this headline">Â¶</a></h3>
<p><strong>Counting parameters</strong></p>
<p>Regularization based pruning methods (soft movement pruning and L0 regularization) rely on the penalty to induce sparsity. The multiplicative coefficient controls the sparsity level.
To obtain the effective sparsity level in the encoder, we simply count the number of activated (non-null) weights:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python examples/movement-pruning/counts_parameters.py <span class="se">\</span>
    --pruning_method sigmoied_threshold <span class="se">\</span>
    --threshold <span class="m">0</span>.1 <span class="se">\</span>
    --serialization_dir <span class="nv">$SERIALIZATION_DIR</span>
</pre></div>
</div>
<p><strong>Pruning once for all</strong></p>
<p>Once the model has been fine-pruned, the pruned weights can be set to 0. once for all (reducing the amount of information to store). In our running experiments, we can convert a <code class="docutils literal notranslate"><span class="pre">MaskedBertForQuestionAnswering</span></code> (a BERT model augmented to enable on-the-fly pruning capabilities) to a standard <code class="docutils literal notranslate"><span class="pre">BertForQuestionAnswering</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python examples/movement-pruning/bertarize.py <span class="se">\</span>
    --pruning_method sigmoied_threshold <span class="se">\</span>
    --threshold <span class="m">0</span>.1 <span class="se">\</span>
    --model_name_or_path <span class="nv">$SERIALIZATION_DIR</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="hyper-parameters">
<h2>Hyper-parameters<a class="headerlink" href="#hyper-parameters" title="Permalink to this headline">Â¶</a></h2>
<p>For reproducibility purposes, we share the detailed results presented in the paper. These <a class="reference external" href="https://docs.google.com/spreadsheets/d/17JgRq_OFFTniUrz6BZWW_87DjFkKXpI1kYDSsseT_7g/edit?usp=sharing">tables</a> exhaustively describe the individual hyper-parameters used for each data point.</p>
</div>
<div class="section" id="inference-speed">
<h2>Inference speed<a class="headerlink" href="#inference-speed" title="Permalink to this headline">Â¶</a></h2>
<p>Early experiments show that even though models fine-pruned with (soft) movement pruning are extremely sparse, they do not benefit from significant improvement in terms of inference speed when using the standard PyTorch inference.
We are currently benchmarking and exploring inference setups specifically for sparse architectures.
In particular, hardware manufacturers are announcing devices that will speedup inference for sparse networks considerably.</p>
</div>
<div class="section" id="citation">
<h2>Citation<a class="headerlink" href="#citation" title="Permalink to this headline">Â¶</a></h2>
<p>If you find this resource useful, please consider citing the following paper:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@article</span><span class="p">{</span><span class="n">sanh2020movement</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="p">{</span><span class="n">Movement</span> <span class="n">Pruning</span><span class="p">:</span> <span class="n">Adaptive</span> <span class="n">Sparsity</span> <span class="n">by</span> <span class="n">Fine</span><span class="o">-</span><span class="n">Tuning</span><span class="p">},</span>
    <span class="n">author</span><span class="o">=</span><span class="p">{</span><span class="n">Victor</span> <span class="n">Sanh</span> <span class="ow">and</span> <span class="n">Thomas</span> <span class="n">Wolf</span> <span class="ow">and</span> <span class="n">Alexander</span> <span class="n">M</span><span class="o">.</span> <span class="n">Rush</span><span class="p">},</span>
    <span class="n">year</span><span class="o">=</span><span class="p">{</span><span class="mi">2020</span><span class="p">},</span>
    <span class="n">eprint</span><span class="o">=</span><span class="p">{</span><span class="mf">2005.07683</span><span class="p">},</span>
    <span class="n">archivePrefix</span><span class="o">=</span><span class="p">{</span><span class="n">arXiv</span><span class="p">},</span>
    <span class="n">primaryClass</span><span class="o">=</span><span class="p">{</span><span class="n">cs</span><span class="o">.</span><span class="n">CL</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, IntelÂ® Neural Compressor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>