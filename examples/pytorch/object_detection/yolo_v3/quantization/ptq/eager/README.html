<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Step-by-Step &mdash; Intel® Neural Compressor  documentation</title><link rel="stylesheet" href="../../../../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../../../../../" src="../../../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../../../_static/jquery.js"></script>
        <script src="../../../../../../../_static/underscore.js"></script>
        <script src="../../../../../../../_static/doctools.js"></script>
    <script src="../../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../../../../index.html" class="icon icon-home"> Intel® Neural Compressor
          </a>
              <div class="version">
                1.14.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../README.html">Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../docs/examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../api-documentation/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../docs/doclist.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../docs/releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../docs/contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../docs/legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../../index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../../index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Step-by-Step</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../../_sources/examples/pytorch/object_detection/yolo_v3/quantization/ptq/eager/README.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="step-by-step">
<h1>Step-by-Step<a class="headerlink" href="#step-by-step" title="Permalink to this headline">¶</a></h1>
<p>This document describes the step-by-step instructions for reproducing PyTorch YOLO v3 tuning results with Intel® Neural Compressor.</p>
<blockquote>
<div><p><strong>Note</strong></p>
<p>PyTorch quantization implementation in imperative path has limitation on automatically execution.
It requires to manually add QuantStub and DequantStub for quantizable ops, it also requires to manually do fusion operation.
Neural Compressor requires users to complete these two manual steps before triggering auto-tuning process.
For details, please refer to https://pytorch.org/docs/stable/quantization.html</p>
</div></blockquote>
</div>
<div class="section" id="prerequisite">
<h1>Prerequisite<a class="headerlink" href="#prerequisite" title="Permalink to this headline">¶</a></h1>
<div class="section" id="installation">
<h2>1. Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> examples/pytorch/object_detection/yolo_v3/quantization/ptq/eager
pip install -r requirements.txt
</pre></div>
</div>
</div>
<div class="section" id="prepare-dataset">
<h2>2. Prepare Dataset<a class="headerlink" href="#prepare-dataset" title="Permalink to this headline">¶</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash get_coco_dataset.sh
</pre></div>
</div>
</div>
<div class="section" id="prepare-weights">
<h2>3. Prepare Weights<a class="headerlink" href="#prepare-weights" title="Permalink to this headline">¶</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash download_weights.sh
</pre></div>
</div>
</div>
</div>
<div class="section" id="run">
<h1>Run<a class="headerlink" href="#run" title="Permalink to this headline">¶</a></h1>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python test.py --weights_path weights/yolov3.weights -t
</pre></div>
</div>
</div>
<div class="section" id="examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-yolov3">
<h1>Examples Of Enabling Neural Compressor Auto Tuning On PyTorch YOLOV3<a class="headerlink" href="#examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-yolov3" title="Permalink to this headline">¶</a></h1>
<p>This is a tutorial of how to enable a PyTorch model with Intel® Neural Compressor.</p>
</div>
<div class="section" id="user-code-analysis">
<h1>User Code Analysis<a class="headerlink" href="#user-code-analysis" title="Permalink to this headline">¶</a></h1>
<p>Intel® Neural Compressor supports three usage as below:</p>
<ol class="simple">
<li><p>User only provide fp32 “model”, and configure calibration dataset, evaluation dataset and metric in model-specific yaml config file.</p></li>
<li><p>User provide fp32 “model”, calibration dataset “q_dataloader” and evaluation dataset “eval_dataloader”, and configure metric in tuning.metric field of model-specific yaml config file.</p></li>
<li><p>User specifies fp32 “model”, calibration dataset “q_dataloader” and a custom “eval_func” which encapsulates the evaluation dataset and metric by itself.</p></li>
</ol>
<p>Here we integrate PyTorch YOLO V3 with Intel® Neural Compressor by the third use case for simplicity.</p>
<div class="section" id="write-yaml-config-file">
<h2>Write Yaml Config File<a class="headerlink" href="#write-yaml-config-file" title="Permalink to this headline">¶</a></h2>
<p>In examples directory, there is a template.yaml. We could remove most of the items and only keep mandatory item for tuning.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1">#conf.yaml</span>

<span class="nt">framework</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pytorch</span>

<span class="nt">tuning</span><span class="p">:</span>
    <span class="nt">accuracy_criterion</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="nt">relative</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.01</span>
    <span class="nt">timeout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">random_seed</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">9527</span>
</pre></div>
</div>
<p>Here we set accuracy target as tolerating 0.01 relative accuracy loss of baseline. The default tuning strategy is basic strategy. The timeout 0 means unlimited tuning time until accuracy target is met, but the result maybe is not a model of best accuracy and performance.</p>
</div>
<div class="section" id="prepare">
<h2>Prepare<a class="headerlink" href="#prepare" title="Permalink to this headline">¶</a></h2>
<p>PyTorch quantization requires two manual steps:</p>
<ol class="simple">
<li><p>Add QuantStub and DeQuantStub for all quantizable ops.</p></li>
<li><p>Fuse possible patterns, such as Conv + Relu and Conv + BN + Relu.</p></li>
</ol>
<p>The related code please refer to examples/pytorch/object_detection/yolo_v3/quantization/ptq/eager/models.py.</p>
</div>
<div class="section" id="code-update">
<h2>Code Update<a class="headerlink" href="#code-update" title="Permalink to this headline">¶</a></h2>
<p>After prepare step is done, we just need update test.py like below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">yolo_dataLoader</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">model_type</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loader</span> <span class="o">=</span> <span class="n">loader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">batch_size</span>
    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="p">:</span>
            <span class="c1"># Extract labels</span>
            <span class="n">labels</span> <span class="o">+=</span> <span class="n">targets</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="c1"># Rescale target</span>
            <span class="n">targets</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">=</span> <span class="n">xywh2xyxy</span><span class="p">(</span><span class="n">targets</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:])</span>
            <span class="n">targets</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">*=</span> <span class="n">opt</span><span class="o">.</span><span class="n">img_size</span>

            <span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span>
            <span class="n">imgs</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">Tensor</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">targets</span>
<span class="k">def</span> <span class="nf">eval_func</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">AP</span><span class="p">,</span> <span class="n">f1</span><span class="p">,</span> <span class="n">ap_class</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">path</span><span class="o">=</span><span class="n">valid_path</span><span class="p">,</span>
        <span class="n">iou_thres</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">iou_thres</span><span class="p">,</span>
        <span class="n">conf_thres</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">conf_thres</span><span class="p">,</span>
        <span class="n">nms_thres</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">nms_thres</span><span class="p">,</span>
        <span class="n">img_size</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">img_size</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">AP</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fuse_model</span><span class="p">()</span>
<span class="kn">from</span> <span class="nn">neural_compressor.experimental</span> <span class="kn">import</span> <span class="n">Quantization</span><span class="p">,</span> <span class="n">common</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">ListDataset</span><span class="p">(</span><span class="n">valid_path</span><span class="p">,</span> <span class="n">img_size</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">img_size</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">multiscale</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">collate_fn</span>
<span class="p">)</span>
<span class="n">nc_dataloader</span> <span class="o">=</span> <span class="n">yolo_dataLoader</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
<span class="n">quantizer</span> <span class="o">=</span> <span class="n">Quantization</span><span class="p">(</span><span class="s2">&quot;./conf.yaml&quot;</span><span class="p">)</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">common</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">calib_dataloader</span> <span class="o">=</span> <span class="n">nc_dataloader</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">eval_func</span> <span class="o">=</span> <span class="n">eval_func</span>
<span class="n">q_model</span> <span class="o">=</span> <span class="n">quantizer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
<p>The quantizer.fit() function will return a best quantized model during timeout constrain.</p>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Neural Compressor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>